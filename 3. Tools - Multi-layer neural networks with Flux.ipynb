{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple neural network layers with `Flux.jl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous notebook, we saw that one layer of neurons wasn't enough to distinguish between three types of fruit (apples, bananas *and* grapes), since the data is quite complex. To solve this problem, we need to use more layers, so heading into the territory of **deep learning**!\n",
    "\n",
    "By adding another layer between the inputs and the output neurons, a so-called \"hidden layer\", we will get our first serious **neural network**, looking something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip0000\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip0000)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip0001\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip0000)\" d=\"\n",
       "M182.008 1487.47 L2352.76 1487.47 L2352.76 47.2441 L182.008 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip0002\">\n",
       "    <rect x=\"182\" y=\"47\" width=\"2172\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  564.03,967.161 771.838,967.161 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  564.03,567.53 771.838,567.53 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0002)\" d=\"\n",
       "M947.676 967.161 L947.277 959.182 L946.083 951.282 L944.107 943.542 L941.367 936.037 L937.892 928.843 L933.716 922.032 L928.881 915.671 L923.435 909.826 L917.433 904.553 \n",
       "  L910.935 899.906 L904.004 895.93 L896.712 892.667 L889.13 890.148 L881.335 888.398 L873.404 887.435 L865.416 887.269 L857.452 887.901 L849.591 889.325 L841.911 891.527 \n",
       "  L834.489 894.485 L827.4 898.168 L820.713 902.541 L814.497 907.56 L808.813 913.174 L803.718 919.328 L799.262 925.959 L795.491 933.002 L792.442 940.387 L790.145 948.039 \n",
       "  L788.624 955.882 L787.893 963.838 L787.96 971.827 L788.824 979.769 L790.477 987.586 L792.903 995.198 L796.075 1002.53 L799.965 1009.51 L804.531 1016.06 L809.729 1022.13 \n",
       "  L815.507 1027.65 L821.807 1032.56 L828.565 1036.82 L835.716 1040.39 L843.186 1043.22 L850.902 1045.29 L858.786 1046.58 L866.76 1047.08 L874.744 1046.78 L882.657 1045.69 \n",
       "  L890.422 1043.8 L897.961 1041.16 L905.197 1037.77 L912.059 1033.68 L918.479 1028.93 L924.392 1023.55 L929.738 1017.62 L934.466 1011.18 L938.526 1004.3 L941.88 997.044 \n",
       "  L944.493 989.494 L946.339 981.721 L947.4 973.802 L947.676 967.161  Z\n",
       "  \" fill=\"#008000\" fill-rule=\"evenodd\" fill-opacity=\"0.5\"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  947.676,967.161 947.277,959.182 946.083,951.282 944.107,943.542 941.367,936.037 937.892,928.843 933.716,922.032 928.881,915.671 923.435,909.826 917.433,904.553 \n",
       "  910.935,899.906 904.004,895.93 896.712,892.667 889.13,890.148 881.335,888.398 873.404,887.435 865.416,887.269 857.452,887.901 849.591,889.325 841.911,891.527 \n",
       "  834.489,894.485 827.4,898.168 820.713,902.541 814.497,907.56 808.813,913.174 803.718,919.328 799.262,925.959 795.491,933.002 792.442,940.387 790.145,948.039 \n",
       "  788.624,955.882 787.893,963.838 787.96,971.827 788.824,979.769 790.477,987.586 792.903,995.198 796.075,1002.53 799.965,1009.51 804.531,1016.06 809.729,1022.13 \n",
       "  815.507,1027.65 821.807,1032.56 828.565,1036.82 835.716,1040.39 843.186,1043.22 850.902,1045.29 858.786,1046.58 866.76,1047.08 874.744,1046.78 882.657,1045.69 \n",
       "  890.422,1043.8 897.961,1041.16 905.197,1037.77 912.059,1033.68 918.479,1028.93 924.392,1023.55 929.738,1017.62 934.466,1011.18 938.526,1004.3 941.88,997.044 \n",
       "  944.493,989.494 946.339,981.721 947.4,973.802 947.676,967.161 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0002)\" d=\"\n",
       "M947.676 567.53 L947.277 559.55 L946.083 551.651 L944.107 543.91 L941.367 536.405 L937.892 529.211 L933.716 522.4 L928.881 516.04 L923.435 510.194 L917.433 504.921 \n",
       "  L910.935 500.274 L904.004 496.299 L896.712 493.035 L889.13 490.516 L881.335 488.766 L873.404 487.803 L865.416 487.637 L857.452 488.269 L849.591 489.693 L841.911 491.895 \n",
       "  L834.489 494.853 L827.4 498.536 L820.713 502.909 L814.497 507.928 L808.813 513.542 L803.718 519.696 L799.262 526.327 L795.491 533.371 L792.442 540.755 L790.145 548.407 \n",
       "  L788.624 556.25 L787.893 564.206 L787.96 572.195 L788.824 580.138 L790.477 587.954 L792.903 595.566 L796.075 602.899 L799.965 609.877 L804.531 616.433 L809.729 622.5 \n",
       "  L815.507 628.018 L821.807 632.931 L828.565 637.191 L835.716 640.755 L843.186 643.588 L850.902 645.66 L858.786 646.952 L866.76 647.45 L874.744 647.149 L882.657 646.053 \n",
       "  L890.422 644.173 L897.961 641.527 L905.197 638.141 L912.059 634.05 L918.479 629.294 L924.392 623.921 L929.738 617.984 L934.466 611.544 L938.526 604.663 L941.88 597.412 \n",
       "  L944.493 589.862 L946.339 582.089 L947.4 574.171 L947.676 567.53  Z\n",
       "  \" fill=\"#008000\" fill-rule=\"evenodd\" fill-opacity=\"0.5\"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  947.676,567.53 947.277,559.55 946.083,551.651 944.107,543.91 941.367,536.405 937.892,529.211 933.716,522.4 928.881,516.04 923.435,510.194 917.433,504.921 \n",
       "  910.935,500.274 904.004,496.299 896.712,493.035 889.13,490.516 881.335,488.766 873.404,487.803 865.416,487.637 857.452,488.269 849.591,489.693 841.911,491.895 \n",
       "  834.489,494.853 827.4,498.536 820.713,502.909 814.497,507.928 808.813,513.542 803.718,519.696 799.262,526.327 795.491,533.371 792.442,540.755 790.145,548.407 \n",
       "  788.624,556.25 787.893,564.206 787.96,572.195 788.824,580.138 790.477,587.954 792.903,595.566 796.075,602.899 799.965,609.877 804.531,616.433 809.729,622.5 \n",
       "  815.507,628.018 821.807,632.931 828.565,637.191 835.716,640.755 843.186,643.588 850.902,645.66 858.786,646.952 866.76,647.45 874.744,647.149 882.657,646.053 \n",
       "  890.422,644.173 897.961,641.527 905.197,638.141 912.059,634.05 918.479,629.294 924.392,623.921 929.738,617.984 934.466,611.544 938.526,604.663 941.88,597.412 \n",
       "  944.493,589.862 946.339,582.089 947.4,574.171 947.676,567.53 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0002)\" d=\"\n",
       "M1347.31 1366.79 L1346.91 1358.81 L1345.72 1350.91 L1343.74 1343.17 L1341 1335.67 L1337.52 1328.47 L1333.35 1321.66 L1328.51 1315.3 L1323.07 1309.46 L1317.07 1304.18 \n",
       "  L1310.57 1299.54 L1303.64 1295.56 L1296.34 1292.3 L1288.76 1289.78 L1280.97 1288.03 L1273.04 1287.07 L1265.05 1286.9 L1257.08 1287.53 L1249.22 1288.96 L1241.54 1291.16 \n",
       "  L1234.12 1294.12 L1227.03 1297.8 L1220.35 1302.17 L1214.13 1307.19 L1208.44 1312.81 L1203.35 1318.96 L1198.89 1325.59 L1195.12 1332.63 L1192.07 1340.02 L1189.78 1347.67 \n",
       "  L1188.26 1355.51 L1187.52 1363.47 L1187.59 1371.46 L1188.46 1379.4 L1190.11 1387.22 L1192.53 1394.83 L1195.71 1402.16 L1199.6 1409.14 L1204.16 1415.7 L1209.36 1421.76 \n",
       "  L1215.14 1427.28 L1221.44 1432.2 L1228.2 1436.46 L1235.35 1440.02 L1242.82 1442.85 L1250.53 1444.92 L1258.42 1446.22 L1266.39 1446.71 L1274.38 1446.41 L1282.29 1445.32 \n",
       "  L1290.05 1443.44 L1297.59 1440.79 L1304.83 1437.4 L1311.69 1433.31 L1318.11 1428.56 L1324.02 1423.18 L1329.37 1417.25 L1334.1 1410.81 L1338.16 1403.93 L1341.51 1396.68 \n",
       "  L1344.12 1389.13 L1345.97 1381.35 L1347.03 1373.43 L1347.31 1366.79  Z\n",
       "  \" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"0.5\"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1347.31,1366.79 1346.91,1358.81 1345.72,1350.91 1343.74,1343.17 1341,1335.67 1337.52,1328.47 1333.35,1321.66 1328.51,1315.3 1323.07,1309.46 1317.07,1304.18 \n",
       "  1310.57,1299.54 1303.64,1295.56 1296.34,1292.3 1288.76,1289.78 1280.97,1288.03 1273.04,1287.07 1265.05,1286.9 1257.08,1287.53 1249.22,1288.96 1241.54,1291.16 \n",
       "  1234.12,1294.12 1227.03,1297.8 1220.35,1302.17 1214.13,1307.19 1208.44,1312.81 1203.35,1318.96 1198.89,1325.59 1195.12,1332.63 1192.07,1340.02 1189.78,1347.67 \n",
       "  1188.26,1355.51 1187.52,1363.47 1187.59,1371.46 1188.46,1379.4 1190.11,1387.22 1192.53,1394.83 1195.71,1402.16 1199.6,1409.14 1204.16,1415.7 1209.36,1421.76 \n",
       "  1215.14,1427.28 1221.44,1432.2 1228.2,1436.46 1235.35,1440.02 1242.82,1442.85 1250.53,1444.92 1258.42,1446.22 1266.39,1446.71 1274.38,1446.41 1282.29,1445.32 \n",
       "  1290.05,1443.44 1297.59,1440.79 1304.83,1437.4 1311.69,1433.31 1318.11,1428.56 1324.02,1423.18 1329.37,1417.25 1334.1,1410.81 1338.16,1403.93 1341.51,1396.68 \n",
       "  1344.12,1389.13 1345.97,1381.35 1347.03,1373.43 1347.31,1366.79 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0002)\" d=\"\n",
       "M1347.31 967.161 L1346.91 959.182 L1345.72 951.282 L1343.74 943.542 L1341 936.037 L1337.52 928.843 L1333.35 922.032 L1328.51 915.671 L1323.07 909.826 L1317.07 904.553 \n",
       "  L1310.57 899.906 L1303.64 895.93 L1296.34 892.667 L1288.76 890.148 L1280.97 888.398 L1273.04 887.435 L1265.05 887.269 L1257.08 887.901 L1249.22 889.325 L1241.54 891.527 \n",
       "  L1234.12 894.485 L1227.03 898.168 L1220.35 902.541 L1214.13 907.56 L1208.44 913.174 L1203.35 919.328 L1198.89 925.959 L1195.12 933.002 L1192.07 940.387 L1189.78 948.039 \n",
       "  L1188.26 955.882 L1187.52 963.838 L1187.59 971.827 L1188.46 979.769 L1190.11 987.586 L1192.53 995.198 L1195.71 1002.53 L1199.6 1009.51 L1204.16 1016.06 L1209.36 1022.13 \n",
       "  L1215.14 1027.65 L1221.44 1032.56 L1228.2 1036.82 L1235.35 1040.39 L1242.82 1043.22 L1250.53 1045.29 L1258.42 1046.58 L1266.39 1047.08 L1274.38 1046.78 L1282.29 1045.69 \n",
       "  L1290.05 1043.8 L1297.59 1041.16 L1304.83 1037.77 L1311.69 1033.68 L1318.11 1028.93 L1324.02 1023.55 L1329.37 1017.62 L1334.1 1011.18 L1338.16 1004.3 L1341.51 997.044 \n",
       "  L1344.12 989.494 L1345.97 981.721 L1347.03 973.802 L1347.31 967.161  Z\n",
       "  \" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"0.5\"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1347.31,967.161 1346.91,959.182 1345.72,951.282 1343.74,943.542 1341,936.037 1337.52,928.843 1333.35,922.032 1328.51,915.671 1323.07,909.826 1317.07,904.553 \n",
       "  1310.57,899.906 1303.64,895.93 1296.34,892.667 1288.76,890.148 1280.97,888.398 1273.04,887.435 1265.05,887.269 1257.08,887.901 1249.22,889.325 1241.54,891.527 \n",
       "  1234.12,894.485 1227.03,898.168 1220.35,902.541 1214.13,907.56 1208.44,913.174 1203.35,919.328 1198.89,925.959 1195.12,933.002 1192.07,940.387 1189.78,948.039 \n",
       "  1188.26,955.882 1187.52,963.838 1187.59,971.827 1188.46,979.769 1190.11,987.586 1192.53,995.198 1195.71,1002.53 1199.6,1009.51 1204.16,1016.06 1209.36,1022.13 \n",
       "  1215.14,1027.65 1221.44,1032.56 1228.2,1036.82 1235.35,1040.39 1242.82,1043.22 1250.53,1045.29 1258.42,1046.58 1266.39,1047.08 1274.38,1046.78 1282.29,1045.69 \n",
       "  1290.05,1043.8 1297.59,1041.16 1304.83,1037.77 1311.69,1033.68 1318.11,1028.93 1324.02,1023.55 1329.37,1017.62 1334.1,1011.18 1338.16,1004.3 1341.51,997.044 \n",
       "  1344.12,989.494 1345.97,981.721 1347.03,973.802 1347.31,967.161 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0002)\" d=\"\n",
       "M1347.31 567.53 L1346.91 559.55 L1345.72 551.651 L1343.74 543.91 L1341 536.405 L1337.52 529.211 L1333.35 522.4 L1328.51 516.04 L1323.07 510.194 L1317.07 504.921 \n",
       "  L1310.57 500.274 L1303.64 496.299 L1296.34 493.035 L1288.76 490.516 L1280.97 488.766 L1273.04 487.803 L1265.05 487.637 L1257.08 488.269 L1249.22 489.693 L1241.54 491.895 \n",
       "  L1234.12 494.853 L1227.03 498.536 L1220.35 502.909 L1214.13 507.928 L1208.44 513.542 L1203.35 519.696 L1198.89 526.327 L1195.12 533.371 L1192.07 540.755 L1189.78 548.407 \n",
       "  L1188.26 556.25 L1187.52 564.206 L1187.59 572.195 L1188.46 580.138 L1190.11 587.954 L1192.53 595.566 L1195.71 602.899 L1199.6 609.877 L1204.16 616.433 L1209.36 622.5 \n",
       "  L1215.14 628.018 L1221.44 632.931 L1228.2 637.191 L1235.35 640.755 L1242.82 643.588 L1250.53 645.66 L1258.42 646.952 L1266.39 647.45 L1274.38 647.149 L1282.29 646.053 \n",
       "  L1290.05 644.173 L1297.59 641.527 L1304.83 638.141 L1311.69 634.05 L1318.11 629.294 L1324.02 623.921 L1329.37 617.984 L1334.1 611.544 L1338.16 604.663 L1341.51 597.412 \n",
       "  L1344.12 589.862 L1345.97 582.089 L1347.03 574.171 L1347.31 567.53  Z\n",
       "  \" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"0.5\"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1347.31,567.53 1346.91,559.55 1345.72,551.651 1343.74,543.91 1341,536.405 1337.52,529.211 1333.35,522.4 1328.51,516.04 1323.07,510.194 1317.07,504.921 \n",
       "  1310.57,500.274 1303.64,496.299 1296.34,493.035 1288.76,490.516 1280.97,488.766 1273.04,487.803 1265.05,487.637 1257.08,488.269 1249.22,489.693 1241.54,491.895 \n",
       "  1234.12,494.853 1227.03,498.536 1220.35,502.909 1214.13,507.928 1208.44,513.542 1203.35,519.696 1198.89,526.327 1195.12,533.371 1192.07,540.755 1189.78,548.407 \n",
       "  1188.26,556.25 1187.52,564.206 1187.59,572.195 1188.46,580.138 1190.11,587.954 1192.53,595.566 1195.71,602.899 1199.6,609.877 1204.16,616.433 1209.36,622.5 \n",
       "  1215.14,628.018 1221.44,632.931 1228.2,637.191 1235.35,640.755 1242.82,643.588 1250.53,645.66 1258.42,646.952 1266.39,647.45 1274.38,647.149 1282.29,646.053 \n",
       "  1290.05,644.173 1297.59,641.527 1304.83,638.141 1311.69,634.05 1318.11,629.294 1324.02,623.921 1329.37,617.984 1334.1,611.544 1338.16,604.663 1341.51,597.412 \n",
       "  1344.12,589.862 1345.97,582.089 1347.03,574.171 1347.31,567.53 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0002)\" d=\"\n",
       "M1347.31 167.898 L1346.91 159.918 L1345.72 152.019 L1343.74 144.278 L1341 136.773 L1337.52 129.579 L1333.35 122.768 L1328.51 116.408 L1323.07 110.562 L1317.07 105.289 \n",
       "  L1310.57 100.642 L1303.64 96.6667 L1296.34 93.4031 L1288.76 90.8839 L1280.97 89.1342 L1273.04 88.1715 L1265.05 88.0053 L1257.08 88.6375 L1249.22 90.0615 L1241.54 92.2633 \n",
       "  L1234.12 95.2208 L1227.03 98.9044 L1220.35 103.277 L1214.13 108.296 L1208.44 113.91 L1203.35 120.064 L1198.89 126.695 L1195.12 133.739 L1192.07 141.123 L1189.78 148.775 \n",
       "  L1188.26 156.618 L1187.52 164.574 L1187.59 172.563 L1188.46 180.506 L1190.11 188.322 L1192.53 195.934 L1195.71 203.267 L1199.6 210.246 L1204.16 216.801 L1209.36 222.868 \n",
       "  L1215.14 228.386 L1221.44 233.3 L1228.2 237.56 L1235.35 241.123 L1242.82 243.956 L1250.53 246.028 L1258.42 247.32 L1266.39 247.818 L1274.38 247.517 L1282.29 246.422 \n",
       "  L1290.05 244.541 L1297.59 241.895 L1304.83 238.509 L1311.69 234.418 L1318.11 229.662 L1324.02 224.289 L1329.37 218.352 L1334.1 211.912 L1338.16 205.032 L1341.51 197.78 \n",
       "  L1344.12 190.23 L1345.97 182.457 L1347.03 174.539 L1347.31 167.898  Z\n",
       "  \" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"0.5\"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1347.31,167.898 1346.91,159.918 1345.72,152.019 1343.74,144.278 1341,136.773 1337.52,129.579 1333.35,122.768 1328.51,116.408 1323.07,110.562 1317.07,105.289 \n",
       "  1310.57,100.642 1303.64,96.6667 1296.34,93.4031 1288.76,90.8839 1280.97,89.1342 1273.04,88.1715 1265.05,88.0053 1257.08,88.6375 1249.22,90.0615 1241.54,92.2633 \n",
       "  1234.12,95.2208 1227.03,98.9044 1220.35,103.277 1214.13,108.296 1208.44,113.91 1203.35,120.064 1198.89,126.695 1195.12,133.739 1192.07,141.123 1189.78,148.775 \n",
       "  1188.26,156.618 1187.52,164.574 1187.59,172.563 1188.46,180.506 1190.11,188.322 1192.53,195.934 1195.71,203.267 1199.6,210.246 1204.16,216.801 1209.36,222.868 \n",
       "  1215.14,228.386 1221.44,233.3 1228.2,237.56 1235.35,241.123 1242.82,243.956 1250.53,246.028 1258.42,247.32 1266.39,247.818 1274.38,247.517 1282.29,246.422 \n",
       "  1290.05,244.541 1297.59,241.895 1304.83,238.509 1311.69,234.418 1318.11,229.662 1324.02,224.289 1329.37,218.352 1334.1,211.912 1338.16,205.032 1341.51,197.78 \n",
       "  1344.12,190.23 1345.97,182.457 1347.03,174.539 1347.31,167.898 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0002)\" d=\"\n",
       "M1746.94 1166.98 L1746.54 1159 L1745.35 1151.1 L1743.37 1143.36 L1740.63 1135.85 L1737.16 1128.66 L1732.98 1121.85 L1728.14 1115.49 L1722.7 1109.64 L1716.7 1104.37 \n",
       "  L1710.2 1099.72 L1703.27 1095.75 L1695.98 1092.48 L1688.39 1089.96 L1680.6 1088.21 L1672.67 1087.25 L1664.68 1087.09 L1656.72 1087.72 L1648.85 1089.14 L1641.17 1091.34 \n",
       "  L1633.75 1094.3 L1626.66 1097.98 L1619.98 1102.36 L1613.76 1107.38 L1608.08 1112.99 L1602.98 1119.14 L1598.53 1125.78 L1594.75 1132.82 L1591.71 1140.2 L1589.41 1147.85 \n",
       "  L1587.89 1155.7 L1587.16 1163.65 L1587.22 1171.64 L1588.09 1179.59 L1589.74 1187.4 L1592.17 1195.01 L1595.34 1202.35 L1599.23 1209.33 L1603.79 1215.88 L1608.99 1221.95 \n",
       "  L1614.77 1227.47 L1621.07 1232.38 L1627.83 1236.64 L1634.98 1240.2 L1642.45 1243.04 L1650.17 1245.11 L1658.05 1246.4 L1666.02 1246.9 L1674.01 1246.6 L1681.92 1245.5 \n",
       "  L1689.69 1243.62 L1697.22 1240.97 L1704.46 1237.59 L1711.32 1233.5 L1717.74 1228.74 L1723.66 1223.37 L1729 1217.43 L1733.73 1210.99 L1737.79 1204.11 L1741.14 1196.86 \n",
       "  L1743.76 1189.31 L1745.6 1181.54 L1746.66 1173.62 L1746.94 1166.98  Z\n",
       "  \" fill=\"#ff0000\" fill-rule=\"evenodd\" fill-opacity=\"0.5\"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1746.94,1166.98 1746.54,1159 1745.35,1151.1 1743.37,1143.36 1740.63,1135.85 1737.16,1128.66 1732.98,1121.85 1728.14,1115.49 1722.7,1109.64 1716.7,1104.37 \n",
       "  1710.2,1099.72 1703.27,1095.75 1695.98,1092.48 1688.39,1089.96 1680.6,1088.21 1672.67,1087.25 1664.68,1087.09 1656.72,1087.72 1648.85,1089.14 1641.17,1091.34 \n",
       "  1633.75,1094.3 1626.66,1097.98 1619.98,1102.36 1613.76,1107.38 1608.08,1112.99 1602.98,1119.14 1598.53,1125.78 1594.75,1132.82 1591.71,1140.2 1589.41,1147.85 \n",
       "  1587.89,1155.7 1587.16,1163.65 1587.22,1171.64 1588.09,1179.59 1589.74,1187.4 1592.17,1195.01 1595.34,1202.35 1599.23,1209.33 1603.79,1215.88 1608.99,1221.95 \n",
       "  1614.77,1227.47 1621.07,1232.38 1627.83,1236.64 1634.98,1240.2 1642.45,1243.04 1650.17,1245.11 1658.05,1246.4 1666.02,1246.9 1674.01,1246.6 1681.92,1245.5 \n",
       "  1689.69,1243.62 1697.22,1240.97 1704.46,1237.59 1711.32,1233.5 1717.74,1228.74 1723.66,1223.37 1729,1217.43 1733.73,1210.99 1737.79,1204.11 1741.14,1196.86 \n",
       "  1743.76,1189.31 1745.6,1181.54 1746.66,1173.62 1746.94,1166.98 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0002)\" d=\"\n",
       "M1746.94 767.345 L1746.54 759.366 L1745.35 751.467 L1743.37 743.726 L1740.63 736.221 L1737.16 729.027 L1732.98 722.216 L1728.14 715.855 L1722.7 710.01 L1716.7 704.737 \n",
       "  L1710.2 700.09 L1703.27 696.114 L1695.98 692.851 L1688.39 690.332 L1680.6 688.582 L1672.67 687.619 L1664.68 687.453 L1656.72 688.085 L1648.85 689.509 L1641.17 691.711 \n",
       "  L1633.75 694.669 L1626.66 698.352 L1619.98 702.725 L1613.76 707.744 L1608.08 713.358 L1602.98 719.512 L1598.53 726.143 L1594.75 733.187 L1591.71 740.571 L1589.41 748.223 \n",
       "  L1587.89 756.066 L1587.16 764.022 L1587.22 772.011 L1588.09 779.953 L1589.74 787.77 L1592.17 795.382 L1595.34 802.714 L1599.23 809.693 L1603.79 816.249 L1608.99 822.316 \n",
       "  L1614.77 827.834 L1621.07 832.747 L1627.83 837.007 L1634.98 840.571 L1642.45 843.404 L1650.17 845.476 L1658.05 846.768 L1666.02 847.266 L1674.01 846.965 L1681.92 845.869 \n",
       "  L1689.69 843.989 L1697.22 841.342 L1704.46 837.957 L1711.32 833.866 L1717.74 829.11 L1723.66 823.737 L1729 817.8 L1733.73 811.36 L1737.79 804.479 L1741.14 797.228 \n",
       "  L1743.76 789.678 L1745.6 781.905 L1746.66 773.986 L1746.94 767.345  Z\n",
       "  \" fill=\"#ff0000\" fill-rule=\"evenodd\" fill-opacity=\"0.5\"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1746.94,767.345 1746.54,759.366 1745.35,751.467 1743.37,743.726 1740.63,736.221 1737.16,729.027 1732.98,722.216 1728.14,715.855 1722.7,710.01 1716.7,704.737 \n",
       "  1710.2,700.09 1703.27,696.114 1695.98,692.851 1688.39,690.332 1680.6,688.582 1672.67,687.619 1664.68,687.453 1656.72,688.085 1648.85,689.509 1641.17,691.711 \n",
       "  1633.75,694.669 1626.66,698.352 1619.98,702.725 1613.76,707.744 1608.08,713.358 1602.98,719.512 1598.53,726.143 1594.75,733.187 1591.71,740.571 1589.41,748.223 \n",
       "  1587.89,756.066 1587.16,764.022 1587.22,772.011 1588.09,779.953 1589.74,787.77 1592.17,795.382 1595.34,802.714 1599.23,809.693 1603.79,816.249 1608.99,822.316 \n",
       "  1614.77,827.834 1621.07,832.747 1627.83,837.007 1634.98,840.571 1642.45,843.404 1650.17,845.476 1658.05,846.768 1666.02,847.266 1674.01,846.965 1681.92,845.869 \n",
       "  1689.69,843.989 1697.22,841.342 1704.46,837.957 1711.32,833.866 1717.74,829.11 1723.66,823.737 1729,817.8 1733.73,811.36 1737.79,804.479 1741.14,797.228 \n",
       "  1743.76,789.678 1745.6,781.905 1746.66,773.986 1746.94,767.345 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip0002)\" d=\"\n",
       "M1746.94 367.714 L1746.54 359.734 L1745.35 351.835 L1743.37 344.094 L1740.63 336.589 L1737.16 329.395 L1732.98 322.584 L1728.14 316.224 L1722.7 310.378 L1716.7 305.105 \n",
       "  L1710.2 300.458 L1703.27 296.483 L1695.98 293.219 L1688.39 290.7 L1680.6 288.95 L1672.67 287.987 L1664.68 287.821 L1656.72 288.453 L1648.85 289.877 L1641.17 292.079 \n",
       "  L1633.75 295.037 L1626.66 298.72 L1619.98 303.093 L1613.76 308.112 L1608.08 313.726 L1602.98 319.88 L1598.53 326.511 L1594.75 333.555 L1591.71 340.939 L1589.41 348.591 \n",
       "  L1587.89 356.434 L1587.16 364.39 L1587.22 372.379 L1588.09 380.322 L1589.74 388.138 L1592.17 395.75 L1595.34 403.083 L1599.23 410.061 L1603.79 416.617 L1608.99 422.684 \n",
       "  L1614.77 428.202 L1621.07 433.115 L1627.83 437.375 L1634.98 440.939 L1642.45 443.772 L1650.17 445.844 L1658.05 447.136 L1666.02 447.634 L1674.01 447.333 L1681.92 446.237 \n",
       "  L1689.69 444.357 L1697.22 441.711 L1704.46 438.325 L1711.32 434.234 L1717.74 429.478 L1723.66 424.105 L1729 418.168 L1733.73 411.728 L1737.79 404.848 L1741.14 397.596 \n",
       "  L1743.76 390.046 L1745.6 382.273 L1746.66 374.355 L1746.94 367.714  Z\n",
       "  \" fill=\"#ff0000\" fill-rule=\"evenodd\" fill-opacity=\"0.5\"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1746.94,367.714 1746.54,359.734 1745.35,351.835 1743.37,344.094 1740.63,336.589 1737.16,329.395 1732.98,322.584 1728.14,316.224 1722.7,310.378 1716.7,305.105 \n",
       "  1710.2,300.458 1703.27,296.483 1695.98,293.219 1688.39,290.7 1680.6,288.95 1672.67,287.987 1664.68,287.821 1656.72,288.453 1648.85,289.877 1641.17,292.079 \n",
       "  1633.75,295.037 1626.66,298.72 1619.98,303.093 1613.76,308.112 1608.08,313.726 1602.98,319.88 1598.53,326.511 1594.75,333.555 1591.71,340.939 1589.41,348.591 \n",
       "  1587.89,356.434 1587.16,364.39 1587.22,372.379 1588.09,380.322 1589.74,388.138 1592.17,395.75 1595.34,403.083 1599.23,410.061 1603.79,416.617 1608.99,422.684 \n",
       "  1614.77,428.202 1621.07,433.115 1627.83,437.375 1634.98,440.939 1642.45,443.772 1650.17,445.844 1658.05,447.136 1666.02,447.634 1674.01,447.333 1681.92,446.237 \n",
       "  1689.69,444.357 1697.22,441.711 1704.46,438.325 1711.32,434.234 1717.74,429.478 1723.66,424.105 1729,418.168 1733.73,411.728 1737.79,404.848 1741.14,397.596 \n",
       "  1743.76,390.046 1745.6,382.273 1746.66,374.355 1746.94,367.714 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  935.57,1034.98 1199.56,1298.97 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  963.662,967.161 1171.47,967.161 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  935.57,899.342 1199.56,635.349 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  910.643,881.375 1224.49,253.684 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  910.643,653.315 1224.49,1281.01 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  935.57,635.349 1199.56,899.342 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  963.662,567.53 1171.47,567.53 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  935.57,499.71 1199.56,235.717 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1353.17,1323.9 1581.23,1209.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1320.58,1286.99 1613.81,847.149 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1303,1277.74 1631.39,456.765 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1353.17,1010.05 1581.23,1124.08 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1353.17,924.268 1581.23,810.238 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1320.58,887.358 1613.81,447.517 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1320.58,647.333 1613.81,1087.17 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1353.17,610.422 1581.23,724.452 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1353.17,524.637 1581.23,410.607 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1303,256.949 1631.39,1077.93 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1320.58,247.701 1613.81,687.542 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1353.17,210.791 1581.23,324.821 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1762.93,1166.98 1970.73,1166.98 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1762.93,767.345 1970.73,767.345 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0002)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:0.5; fill:none\" points=\"\n",
       "  1762.93,367.714 1970.73,367.714 \n",
       "  \"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"draw_neural_net.jl\")\n",
    "draw_network([2, 4, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue to use two input data and try to classify into three types, so we will have three output neurons. We have chosen to add a single \"hidden layer\" in between, and have arbitrarily chosen to put 4 neurons there.\n",
    "\n",
    "Much of the *art* of deep learning is choosing a suitable structure for the neural network that will allow the model to be sufficiently complex to model the data well, but sufficiently simple to allow the parameters to be learned in a reasonable length of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and process data\n",
    "\n",
    "As before, let's load some pre-processed data using code we've seen in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pkg; Pkg.add(\"Flux\")\n",
    "using Flux\n",
    "using Flux: onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pkg; Pkg.add(\"CSV\")\n",
    "using CSV, DataFrames\n",
    "\n",
    "apples_1 = DataFrame(CSV.File(\"data/Apple_Golden_1.dat\", delim='\\t', normalizenames=true))\n",
    "apples_2 = DataFrame(CSV.File(\"data/Apple_Golden_2.dat\", delim='\\t', normalizenames=true))\n",
    "apples_3 = DataFrame(CSV.File(\"data/Apple_Golden_3.dat\", delim='\\t', normalizenames=true))\n",
    "bananas = DataFrame(CSV.File(\"data/Banana.dat\", delim='\\t', normalizenames=true))\n",
    "grapes_1 = DataFrame(CSV.File(\"data/Grape_White.dat\", delim='\\t', normalizenames=true))\n",
    "grapes_2 = DataFrame(CSV.File(\"data/Grape_White_2.dat\", delim='\\t', normalizenames=true))\n",
    "\n",
    "apples = vcat(apples_1, apples_2, apples_3)\n",
    "grapes = vcat(grapes_1, grapes_2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = :red\n",
    "col2 = :blue\n",
    "\n",
    "x_apples  = [ [apples_1[i, col1], apples_1[i, col2]] for i in 1:size(apples_1)[1] ]\n",
    "append!(x_apples, [ [apples_2[i, col1], apples_2[i, col2]] for i in 1:size(apples_2)[1] ])\n",
    "append!(x_apples, [ [apples_3[i, col1], apples_3[i, col2]] for i in 1:size(apples_3)[1] ])\n",
    "\n",
    "x_bananas = [ [bananas[i, col1], bananas[i, col2]] for i in 1:size(bananas)[1] ]\n",
    "\n",
    "x_grapes = [ [grapes_1[i, col1], grapes_1[i, col2]] for i in 1:size(grapes_1)[1] ]\n",
    "append!(x_grapes, [ [grapes_2[i, col1], grapes_2[i, col2]] for i in 1:size(grapes_2)[1] ])\n",
    "\n",
    "xs = vcat(x_apples, x_bananas, x_grapes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now we wish to classify the three types of fruit, so we again use one-hot vectors to represent the desired outputs $y^{(i)}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ones(length(x_apples)); 2*ones(length(x_bananas)); 3*ones(length(x_grapes))];\n",
    "\n",
    "ys = [onehot(label, 1:3) for label in labels];  # onehotbatch(labels, 1:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data is in `xs` and the one-hot vectors are in `ys`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple layers in Flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tell Flux what structure we want the network to have. We first specify the number of neurons in each layer, and then construct each layer as a `Dense` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 2\n",
    "hidden = 4\n",
    "outputs = 3\n",
    "\n",
    "layer1 = Dense(inputs, hidden, σ)\n",
    "layer2 = Dense(hidden, outputs, σ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stitch together multiple layers to make a multi-layer network, we use Flux's `Chain` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(layer1, layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "\n",
    "What is the internal structure and sub-structure of this `model` object?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `model` understands that it consists of two layers, and:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So both the layers have their own `W` and `b`, just as you might expect -- `Flux` wraps all this up in a way that is structured but easy to use.\n",
    "\n",
    "In particular, using `params` returns *all* the parameters hidden inside the `model` object, that is the pairs $(W, b)$ from both layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now set up a model and we have some training data.\n",
    "How do we train the model on the data?\n",
    "\n",
    "The amazing thing is that the rest of the code in `Flux` is **exactly the same as before**. This is possible thanks to the design of Julia itself, and of the `Flux` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "\n",
    "Train the model as before, now using the popular `ADAM` optimizer. You may need to train the network for longer than before, since we have many more parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x, y) = Flux.mse(model(x), y)\n",
    "data = zip(xs, ys);\n",
    "opt = ADAM(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(loss.(xs, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time for i in 1:100\n",
    "    Flux.train!(loss, params(model), data, opt)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the final values of the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(loss.(xs, ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding it up: batching\n",
    "\n",
    "Remember that in the core of each neuron is matrix-vector multiplication:\n",
    "\n",
    "```julia\n",
    "σ.(W * x .+ b)\n",
    "```\n",
    "\n",
    "What would happen if `x` were a matrix of multiple columns of datapoints?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = rand(3, 2) # shape for 2 inputs, three outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W * xs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W * xs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W * [xs[1] xs[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "\n",
    "Use the `Flux.batch` function to perform a faster training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batcheddata = (Flux.batch(xs), Flux.batch(ys))\n",
    "@time for i in 1:100\n",
    "    Flux.train!(loss, params(model), [batcheddata], opt)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this neural network represent? It is simply a more complicated function with two inputs and three outputs, i.e. a function $f: \\mathbb{R}^2 \\to \\mathbb{R}^3$.\n",
    "Before, with a single layer, each component of the function $f$ basically corresponded to a hyperplane; now it will instead be a **more complicated nonlinear function** of the input data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "\n",
    "Visualize each component of the output separately as a heatmap and/or contours superimposed on the data. Interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "plot(colorbar=false, xlabel=\"average red amount\", ylabel=\"average blue amount\")\n",
    "\n",
    "contour!(0:0.01:1, 0:0.01:1, (x,y)->model([x,y])[1], levels=[0.5], color = cgrad([:red, :red]))\n",
    "contour!(0:0.01:1, 0:0.01:1, (x,y)->model([x,y])[2], levels=[0.5], color = cgrad([:yellow, :yellow]))\n",
    "contour!(0:0.01:1, 0:0.01:1, (x,y)->model([x,y])[3], levels=[0.5], color = cgrad([:green, :green]))\n",
    "\n",
    "scatter!(first.(x_apples), last.(x_apples), color=:red, label=\"apples\")\n",
    "scatter!(first.(x_bananas), last.(x_bananas), color=:yellow, label=\"bananas\")\n",
    "scatter!(first.(x_grapes), last.(x_grapes), color=:green, label=\"grapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the first component, which is supposed to separate apples from non-apples, has been able to learn a set that has a much more complicated shape than simply a hyperplane: the hyperplane has been bent round. Sometimes it's able to encapsulate all the apple data, while sometimes it isn't, depending on how well it learnt.\n",
    "The second component is very successful at separating out the bananas. Since there are some apples mixed in there, it can't be expected to do too much better.\n",
    "The third component separates grapes from the rest pretty successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we have learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an intermediate layer allows the network to start to deform the separating surfaces that it is learning into more complicated, nonlinear (curved) shapes. This allows it to separate data that were previously unable to be separated!\n",
    "\n",
    "However, using only two features means that data from different classes overlaps. To distinguish it we would need to use more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Use three features (red, green and blue) and build a network with one hidden layer. Does this help to distinguish the data better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
